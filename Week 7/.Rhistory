?randomForest
rforest<-randomForest(Crime ~ M + Ed + Po + Wealth + Ineq + Prob, uscrimedata$train, xtest = test_city, keep.forest = TRUE)
summary(rforest)
plot(rforest)
rfpredtrain<-predict(rforest, uscrimedata$train)
rfpredtrain
R2RF <- 1 - (sum((uscrimedata$train$Crime-rfpredtrain)^2)/sum((uscrimedata$train$Crime-mean(rfpredtrain))^2))
R2RF
########Predict
#create test city data frame with the 6 components used in the model
test_city <- c(M = 14.0,Ed = 10.0,
Po = 13.75, Wealth = 3200,
Ineq = 20.1, Prob = 0.04)
test_city <- as.data.frame(t(test_city))
#regression tree
predict(rtree, test_city)
rtpredtest<-predict(rtree, uscrimedata$test)
rtpredtest
R2RTTest <- 1 - (sum((uscrimedata$test$Crime-rtpredtest )^2)/sum((uscrimedata$test$Crime-mean(rtpredtest))^2))
R2RTTest
#random forest
rforest$test
rfpredtest<-predict(rforest, uscrimedata$test)
rfpredtest
R2RFTest <- 1 - (sum((uscrimedata$test$Crime-rfpredtest)^2)/sum((uscrimedata$test$Crime-mean(rfpredtest))^2))
R2RFTest
rtree<-rpart(Crime ~M + Ed + Po + Wealth + Ineq + Prob, uscrimedata$train, xval = 100, minbucket = 2)
rpart.plot(rtree)
summary(rtree)
rtpredtrain<-predict(rtree, uscrimedata$train)
R2RT <- 1 - (sum((uscrimedata$train$Crime-rtpredtrain )^2)/sum((uscrimedata$train$Crime-mean(rtpredtrain))^2))
R2RT
#create randomforest model
?randomForest
rforest<-randomForest(Crime ~ M + Ed + Po + Wealth + Ineq + Prob, uscrimedata$train, xtest = test_city, keep.forest = TRUE)
summary(rforest)
plot(rforest)
rfpredtrain<-predict(rforest, uscrimedata$train)
rfpredtrain
R2RF <- 1 - (sum((uscrimedata$train$Crime-rfpredtrain)^2)/sum((uscrimedata$train$Crime-mean(rfpredtrain))^2))
R2RF
########Predict
#create test city data frame with the 6 components used in the model
test_city <- c(M = 14.0,Ed = 10.0,
Po = 13.75, Wealth = 3200,
Ineq = 20.1, Prob = 0.04)
test_city <- as.data.frame(t(test_city))
#regression tree
predict(rtree, test_city)
rtpredtest<-predict(rtree, uscrimedata$test)
rtpredtest
R2RTTest <- 1 - (sum((uscrimedata$test$Crime-rtpredtest )^2)/sum((uscrimedata$test$Crime-mean(rtpredtest))^2))
R2RTTest
#random forest
rforest$test
rfpredtest<-predict(rforest, uscrimedata$test)
rfpredtest
R2RFTest <- 1 - (sum((uscrimedata$test$Crime-rfpredtest)^2)/sum((uscrimedata$test$Crime-mean(rfpredtest))^2))
R2RFTest
rtree<-rpart(Crime ~M + Ed + Po + Wealth + Ineq + Prob, uscrimedata$train, xval = 100, minbucket = 2)
rpart.plot(rtree)
R2RT
R2RTTest
#regression tree
predict(rtree, test_city)
rforest<-randomForest(Crime ~ M + Ed + Po + Wealth + Ineq + Prob, uscrimedata$train, xtest = test_city, keep.forest = TRUE)
summary(rforest)
plot(rforest)
rfpredtrain<-predict(rforest, uscrimedata$train)
rfpredtrain
summary(rforest)
plot(rforest)
rfpredtrain<-predict(rforest, uscrimedata$train)
rfpredtrain
R2RF <- 1 - (sum((uscrimedata$train$Crime-rfpredtrain)^2)/sum((uscrimedata$train$Crime-mean(rfpredtrain))^2))
R2RF
View(rforest)
rforest$importance
R2RFTest <- 1 - (sum((uscrimedata$test$Crime-rfpredtest)^2)/sum((uscrimedata$test$Crime-mean(rfpredtest))^2))
R2RFTest
#random forest
rforest$test
rpart.plot(rtree)
#####Plotting and Data Cleaning - did not remove potential outliers based on week three analysis
#plot all variables
uscrime_melt = melt(data=uscrimedata, measure.vars = colnames(uscrimedata[,1:15]))
ggplot(data = uscrime_melt, aes(x=value, y=Crime)) +
geom_point() +
facet_wrap(~variable, scales = "free")
#set Directory to data path
setwd('/Users/dave/isye6501/Week 7')
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#Check class and inspect data
class(gcdata)
head(gcdata)
summary(gcdata)
#convert response column from 1 and 2 into 0 and 1 for logistic regression
twotozero<-function(x){
if (x == 2)
x<-0
return(x)
}
#plot predictors
gcdata_melt = melt(data=gcdata, measure.vars = colnames(gcdata[,1:21]))
#plot predictors
gcdata_melt = melt(data=gcdata, measure.vars = colnames(gcdata[,1:20]))
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#Check class and inspect data
class(gcdata)
head(gcdata)
summary(gcdata)
#plot predictors
gcdata_melt = melt(data=gcdata, measure.vars = colnames(gcdata[,1:21]))
ggplot(data = gcdata, aes(x=value, y=V21)) +
geom_point() +
facet_wrap(~variable, scales = "free")
#plot predictors
gcdata_melt = melt(data=gcdata, measure.vars = colnames(gcdata[,1:20]))
ggplot(data = gcdata, aes(x=value, y=V21)) +
geom_point() +
facet_wrap(~variable, scales = "free")
#convert response column from 1 and 2 into 0 and 1 for logistic regression
twotozero<-function(x){
if (x == 2)
x<-0
return(x)
}
gcdata$V21 <- sapply(gcdata$V21, twotozero)
View(gcdata_melt)
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#Check class and inspect data
class(gcdata)
head(gcdata)
summary(gcdata)
#plot predictors
gcdata_melt = melt(data=gcdata, measure.vars = colnames(gcdata[,1:21]))
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#plot predictors
gcdata_melt = melt(data=gcdata, measure.vars = colnames(gcdata[,1:20]))
ggplot(data = gcdata, aes(x=value, y=V21)) +
geom_point() +
facet_wrap(~variable, scales = "free")
plot(gcdata_melt)
plot(gcdata)
#set Directory to data path
setwd('/Users/dave/isye6501/Week 7')
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#Check class and inspect data
class(gcdata)
head(gcdata)
summary(gcdata)
#convert response column from 1 and 2 into 0 and 1 for logistic regression
twotozero<-function(x){
if (x == 2)
x<-0
return(x)
}
gcdata$V21 <- sapply(gcdata$V21, twotozero)
#CREATE TRAIN TEST VAL SPLIT
set.seed(1)
spec = c(train = .7, test = .15, validate = .15)
#CREATE TRAIN TEST VAL SPLIT
set.seed(1)
spec = c(train = .7, test = .15, validate = .15)
g = sample(cut(
seq(nrow(gcdata)),
nrow(gcdata)*cumsum(c(0,spec)),
labels = names(spec)
))
gcdata = split(gcdata, g)
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 653 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V6, data = gcdata$train, family=binomial(link='logit')) #best model
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 653 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V6, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 653 with all factors
logreg<-glm(V21~., data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 653 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V6, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~., data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V4+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~., data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V3+V4+v14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V3+V4+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#V1+V2+V3+V4+V6
#V1+V2+V3+V4+V5+V6+V8+V14 - second best
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
pred
#choosing a threshold based on loss function
pred<-predict(logreg, gcdata$validate)
pred
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$validate, family=binomial(link='logit')) #best model
summary(logreg)
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~., data = gcdata$validate, family=binomial(link='logit')) #best model
summary(logreg)
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V14, data = gcdata$validate, family=binomial(link='logit')) #best model
summary(logreg)
+V4+V5+V6+V8+
+V4+V5+V6+V8+
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$validate, family=binomial(link='logit')) #best model
summary(logreg)
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#choosing a threshold based on loss function
pred<-predict(logreg, gcdata$validate)
pred
l = c()
bin_pred = as.integer(pred>(.1))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
confusion_matrix
loss
bin_pred = as.integer(pred>(.2))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
confusion_matrix
bin_pred = as.integer(pred>(.3))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
confusion_matrix
bin_pred = as.integer(pred>(.4))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
confusion_matrix
#set Directory to data path
setwd('/Users/dave/isye6501/Week 7')
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#Check class and inspect data
class(gcdata)
head(gcdata)
summary(gcdata)
#convert response column from 1 and 2 into 0 and 1 for logistic regression
twotozero<-function(x){
if (x == 2)
x<-0
return(x)
}
gcdata$V21 <- sapply(gcdata$V21, twotozero)
#CREATE TRAIN TEST VAL SPLIT
set.seed(1)
spec = c(train = .7, test = .15, validate = .15)
g = sample(cut(
seq(nrow(gcdata)),
nrow(gcdata)*cumsum(c(0,spec)),
labels = names(spec)
))
gcdata = split(gcdata, g)
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#choosing a threshold based on loss function
pred<-predict(logreg, gcdata$validate)
pred
l = c()
thresh<-.1
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(thresh,loss)
confusion_matrix
loss
thresh<-.2
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(thresh,loss)
confusion_matrix
loss
l = c()
thresholds=c()
thresh<-.1
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
thresh<-.2
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
thresh<-.3
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
thresh<-.4
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
thresh<-.5
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
thresh<-.6
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
thresh<-.7
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
thresh<-.8
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
thresh<-.9
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
plot(l)
plot(l, x = thresholds)
plot(l, Y= "loss", x = thresholds)
plot(l, y = "loss", x = thresholds)
#predict
pred_test<-predict(logreg, gcdata$test)
plot(l, y = loss, x = thresholds)
plot(l, y = l, x = thresholds)
plot(l, x = thresholds)
loss<-l
plot(loss, x = thresholds)
confusion_matrix
thresh<-.1
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
confusion_matrix
plot(confusion_matrix)
table(confusion_matrix)
View(gcdata)
#create table of crime data with headers
uscrimedata<-read.table("uscrime.txt", header = TRUE)
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
View(gcdata)
#set Directory to data path
setwd('/Users/dave/isye6501/Week 7')
#create table of crime data with headers
gcdata<-read.table("germancredit.txt", header = FALSE)
#Check class and inspect data
class(gcdata)
head(gcdata)
summary(gcdata)
#convert response column from 1 and 2 into 0 and 1 for logistic regression
twotozero<-function(x){
if (x == 2)
x<-0
return(x)
}
gcdata$V21 <- sapply(gcdata$V21, twotozero)
#CREATE TRAIN TEST VAL SPLIT
set.seed(1)
spec = c(train = .7, test = .15, validate = .15)
g = sample(cut(
seq(nrow(gcdata)),
nrow(gcdata)*cumsum(c(0,spec)),
labels = names(spec)
))
gcdata = split(gcdata, g)
#build model - choose based on AIC - 706 with all factors
logreg<-glm(V21~V1+V2+V3+V4+V5+V6+V8+V14, data = gcdata$train, family=binomial(link='logit')) #best model
summary(logreg)
#choosing a threshold based on loss function
pred<-predict(logreg, gcdata$validate)
pred
l = c()
thresholds=c()
thresh<-.1
bin_pred = as.integer(pred>(thresh))
confusion_matrix = table(bin_pred,gcdata$validate$V21)
loss = confusion_matrix[2,1] + 5*confusion_matrix[1,2]
l<-c(l,loss)
thresholds<-c(thresholds,thresh)
confusion_matrix
loss
plot(l, x = thresholds)
#predict
pred_test<-predict(logreg, gcdata$test)
bin_pred_test = as.integer(pred_test>(.1))
confusion_matrix_test = table(bin_pred,gcdata$test$V21)
loss = confusion_matrix_test[2,1] + 5*confusion_matrix_test[1,2]
confusion_matrix
loss
confusion_matrix_test
loss
summary(logreg)
confusion_matrix_test
summary(logreg)
View(logreg)
logreg$R
logreg$df.residual
logreg$residuals
