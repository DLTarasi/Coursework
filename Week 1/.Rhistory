#plot each a value - it is clear from this plot that column 5 of the data is by far the
# most predictive.
plot(a)
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
# calculate a0
a0 <- -model@b
a0
# see what the model predicts
pred <- predict(model,data[,1:10])
pred
# see what fraction of the model’s predictions match the actual classification
sum(pred == data[,11]) / nrow(data)
# calculate margin for model
margin = 2/sqrt(sum(a^2))
margin
# call ksvm.  Vanilladot is a simple linear kernel. Changing C changes tradeoff
# between error and margin. Because changes in C values over a large range (between
# .001 and 100000) have minimal impact on the models predictions, we can guess
# that the data is likely well seperated and we don't have to make much tradeoff
# between a large margin and avoiding mistakes.
model <- ksvm(data[,1:10],data[,11],type="C-svc",
kernel="vanilladot",C=90000,scaled=TRUE)
#choose 10000 for c because it is within the range giving minimum error rate at maximum margin.
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
#plot each a value - it is clear from this plot that column 5 of the data is by far the
# most predictive.
plot(a)
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
# calculate a0
a0 <- -model@b
a0
# see what the model predicts
pred <- predict(model,data[,1:10])
pred
# see what fraction of the model’s predictions match the actual classification
sum(pred == data[,11]) / nrow(data)
# calculate margin for model
margin = 2/sqrt(sum(a^2))
margin
# call ksvm.  Vanilladot is a simple linear kernel. Changing C changes tradeoff
# between error and margin. Because changes in C values over a large range (between
# .001 and 100,000) have minimal impact on the models predictions, we can guess
# that the data is likely well seperated and we don't have to make much tradeoff
# between a large margin and avoiding mistakes.
model <- ksvm(data[,1:10],data[,11],type="C-svc",
kernel="vanilladot",C=100000,scaled=TRUE)
#choose 100,000 for c because it is within the range giving minimum error rate at maximum margin.
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
# calculate a0
a0 <- -model@b
# see what the model predicts
pred <- predict(model,data[,1:10])
# see what fraction of the model’s predictions match the actual classification
sum(pred == data[,11]) / nrow(data)
# calculate margin for model
margin = 2/sqrt(sum(a^2))
margin
#
library("kknn")
#set Directory to data path
setwd('/Users/dave/isye6501/Week 1')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
#use train.kknn to find best k value. train.kknn uses leave one out
#cross validation, avoiding the issue mentioned in the HW instructions
train.kknn(formula=V11~.,data=data,kmax=100, kernel="rectangular", distance=2,scale=TRUE)
#generate train/test split
set.seed(101) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#generate train/test split
set.seed(11) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#generate train/test split
set.seed(74) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#generate train/test split
set.seed(123) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#generate train/test split
set.seed(1234) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.8*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#generate train/test split
set.seed(123) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(data), size = floor(.8*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#run kernlab
library("kernlab")
#Set Directory to data path
setwd('/Users/dave/isye6501/Week 1')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
#convert from df to matrix
data<-as.matrix(data)
class(data)
# call ksvm using rbfdot - 99.5% accuracy, but almost certainly overfitting -
# testing on the same data we trained on, and using a very high c value.
model <- ksvm(data[,1:10],data[,11],type="C-svc",kernel="rbfdot",C=10000,scaled=TRUE)
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
a
#plot a
plot(a)
# calculate a0
a0 <- -model@b
a0
# see what the model predicts
pred <- predict(model,data[,1:10])
pred
# see what fraction of the model’s predictions match the actual classification
sum(pred == data[,11]) / nrow(data)
#run kernlab
library("kernlab")
#Set Directory to data path
setwd('/Users/dave/isye6501/Week 1')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
#convert from df to matrix
data<-as.matrix(data)
class(data)
# call ksvm.  Vanilladot is a simple linear kernel. Changing C changes tradeoff
# between error and margin. Because changes in C values over a large range (between
# .001 and 100,000) have minimal impact on the models predictions, we can guess
# that the data is likely well seperated and we don't have to make much tradeoff
# between a large margin and avoiding mistakes.
model <- ksvm(data[,1:10],data[,11],type="C-svc",
kernel="vanilladot",C=100000,scaled=TRUE)
#choose 100,000 for c because it is within the range giving minimum error rate at maximum margin.
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
#plot each a value - it is clear from this plot that column 5 of the data is by far the
# most predictive.
plot(a)
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
# calculate a0
a0 <- -model@b
a0
# see what the model predicts
pred <- predict(model,data[,1:10])
pred
# see what fraction of the model’s predictions match the actual classification
sum(pred == data[,11]) / nrow(data)
# calculate margin for model
margin = 2/sqrt(sum(a^2))
margin
#plot each a value - it is clear from this plot that column 5 of the data is by far the
# most predictive.
plot(a)
#choose 100,000 for c because it is within the range giving minimum error rate at maximum margin.
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
#choose 100,000 for c because it is within the range giving minimum error rate at maximum margin.
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
#choose 100,000 for c because it is within the range giving minimum error rate at maximum margin.
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
#plot each a value - it is clear from this plot that column 5 of the data is by far the
# most predictive.
plot(a)
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
a
a0
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(table(data[,11], data[,5]))
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5], xlab="Predicted", ylab="Actual")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(table(data[,11], data[,5], xlab="Predicted", ylab="Actual"))
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(table(data[,11], data[,5]), xlab="Predicted", ylab="Actual"))
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(table(data[,11], data[,5]), xlab="Predicted", ylab="Actual")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(array(data[,11], data[,5]), xlab="Predicted", ylab="Actual")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(table(data[,11], data[,5]), xlab="Predicted", ylab="Actual")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(as.table(data[,11], data[,5]), xlab="Predicted", ylab="Actual")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
plot(table(data[,11], data[,5]), xlab="Predicted", ylab="Actual")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5]), xlab="Predicted", ylab="Actual"
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
cm<-table(data[,11], data[,5])
colnames(cm)<-c(0,1)
rownames(cm)<-c(1,0)
cm
plot(cm)
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
cm<-c(data[,11], data[,5])
colnames(cm)<-c(0,1)
rownames(cm)<-c(1,0)
plot(cm)
plot(as.table(cm)
plot(as.table(cm))
cm<-as.table(cm)
cm
plot(cm)
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
table(data[,11], data[,5])
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
xtable(data[,11], data[,5])
install.packages("xtable")
library("xtable", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
xtable(data[,11], data[,5])
#create confusion matrix of attribute 5 and results - from this matrix it appears
# that attribute 5 is deterimative in about 86% of cases (286+278/654=.862).
# This is very close to what our SVM predicts.
xtable(table(data[,11], data[,5]))
#
library("kknn")
#set Directory to data path
setwd('/Users/dave/isye6501/Week 1')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
#use train.kknn to find best k value. train.kknn uses leave one out
#cross validation, avoiding the issue mentioned in the HW instructions
train.kknn(formula=V11~.,data=data,kmax=100, kernel="rectangular", distance=2,scale=TRUE)
#generate train/test split
set.seed(123) # Set seed used in sampling so that we can reproduce sample
# sample 80% of data and assign to test set. Assign remaining 20% to test.
sample <- sample.int(n = nrow(data), size = floor(.8*nrow(data)), replace = FALSE)
train <- data[sample, ]
test  <- data[-sample, ]
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=20,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=12,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=1,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=100,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=24,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=23,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=21,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=20,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
#create model
model<-kknn(V11~.,train,test,k=19,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy
accu <- sum(diag(confusion))/nrow(test)
accu
