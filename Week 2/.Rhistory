geom_encircle(data=ss1, s_shape=0.5, expand=0.1, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.1, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.1, colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.1, expand=0.1, colour="red") +
geom_encircle(data=ss2, s_shape=0.1, expand=0.1, colour="green") +
geom_encircle(data=ss3, s_shape=0.1, expand=0.1, colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.1, expand=0.5, colour="red") +
geom_encircle(data=ss2, s_shape=0.1, expand=0.5, colour="green") +
geom_encircle(data=ss3, s_shape=0.1, expand=0.5, colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.1, expand=0., colour="red") +
geom_encircle(data=ss2, s_shape=0.1, expand=0., colour="green") +
geom_encircle(data=ss3, s_shape=0.1, expand=0., colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0., colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0., colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0., colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.01, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.01, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.01, colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.05, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.05, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.05, colour="blue")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="blue")
#load ggplot and ggalt for plotting results
library(ggplot2)
library(ggalt)
#load and inspect data
data(iris)
head(iris)
summary(iris)
class(iris)
#plot relationships between combo of predictors based on thise plot it looks
#like petal length and petal width are best predictors
plot(iris)
#initialize model, test different ks and predictors
iris_cluster_model <- kmeans(iris[,3:4], centers=3)
iris_cluster_model
#create table of clusters and species
Clusters <- as.factor(iris_cluster_model$cluster)
Clusters
table(Clusters, iris$Species)
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
#plot petal length vs. width, color points by cluster - very close to species
ss1<-subset(iris, iris_cluster_model$cluster == 1)
ss2<-subset(iris, iris_cluster_model$cluster == 2)
ss3<-subset(iris, iris_cluster_model$cluster == 3)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="blue")
#generate train/test split
# sample 85% of data and assign to train set. Assign remaining 15% to test set
sample <- sample.int(n = nrow(data), size = floor(.85*nrow(data)), replace = FALSE)
train <- data[sample, ]
test  <- data[-sample, ]
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=13, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
library(data.table)
library("kknn")
#set Directory to data path
setwd('/Users/dave/isye6501/Week 2')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
set.seed(10) # Set seed used in sampling so that we can reproduce sample
#generate train/test split
# sample 85% of data and assign to train set. Assign remaining 15% to test set
sample <- sample.int(n = nrow(data), size = floor(.85*nrow(data)), replace = FALSE)
train <- data[sample, ]
test  <- data[-sample, ]
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=13, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
source('~/isye6501/Week 2/3.1.a.R', echo=TRUE)
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=11, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=12, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=13, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=14, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=10, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=15, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=17, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=22, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=7, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=8, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=9, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=7, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks 13 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=6, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#final test with best hyperparameters
model<-kknn(V11~.,train,test,k=17,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(test)
accu
library(data.table)
library("kknn")
#set Directory to data path
setwd('/Users/dave/isye6501/Week 2')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
set.seed(10) # Set seed used in sampling so that we can reproduce sample
#generate train/test split
# sample 85% of data and assign to train set. Assign remaining 15% to test set
sample <- sample.int(n = nrow(data), size = floor(.85*nrow(data)), replace = FALSE)
train <- data[sample, ]
test  <- data[-sample, ]
#use cv.kknn to to perform k-fold cross validation. Test variety of Ks. 7 was best accuracy at 86%
cv<-cv.kknn(formula=V11~.,data=train, k=7, kernel="rectangular", distance=2,scale=TRUE, kcv = 10)
#convert cv.kknn output to data table then round response variable to convert
#continuous variable to 0 or 1
cv = data.table(cv[[1]])
cv$yhat <- round(cv$yhat)
cv
# Cross Validation Accuracy - compare actual vs. predicted
table(cv$y == cv$yhat)
prop.table(table(cv$y == cv$yhat))
#final test with best hyperparameters
model<-kknn(V11~.,train,test,k=17,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
#final test with best hyperparameters
model<-kknn(V11~.,train,test,k=7,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(test)
accu
library("kknn")
#set Directory to data path
setwd('/Users/dave/isye6501/Week 2')
#create table of credit card data - no headers
data<-read.table("credit_card_data.txt", header = FALSE)
#Check class and inspect data
class(data)
head(data)
summary(data)
#generate train/test/val split
set.seed(10) # Set seed used in sampling so that we can reproduce sample
# sample 70% of data and assign to train set. Split remaining 30% 1/2 to validation
# and 1/2 to test set (so 15% of total to validation, 15% of total data set to test).
sample <- sample.int(n = nrow(data), size = floor(.7*nrow(data)), replace = FALSE)
sample2 <- sample.int(n = nrow(data[-sample,]), size = floor(.5*nrow(data[-sample,])), replace = FALSE)
train <- data[sample, ]
val <- data[sample2,]
test  <- data[-sample, ][-sample2,]
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=7,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#final test using the test set.
model<-kknn(V11~.,train,test,k=7,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(test)
accu
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=12,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=22,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=7,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=15,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=3,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#final test using the test set.
model<-kknn(V11~.,train,test,k=7,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(test)
accu
#final test using the test set.
model<-kknn(V11~.,train,test,k=3,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(test[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(test)
accu
#create model - try a variety of hyperparameters using the validation set
model<-kknn(V11~.,train,val,k=3,distance=2,kernel="rectangular")
#get predictions and convert from continuous reponse to binary by rounding to 0 or 1
predictions<-round(fitted(model))
predictions
# generate confusion matrix - 0,0 means model predicts 0 and actual was 0
confusion <- table(val[,11], predictions)
confusion
# Compute accuracy on val
accu <- sum(diag(confusion))/nrow(val)
accu
#load ggplot and ggalt for plotting results
library(ggplot2)
library(ggalt)
#load and inspect data
data(iris)
head(iris)
summary(iris)
class(iris)
#plot relationships between combo of predictors based on thise plot it looks
#like petal length and petal width are best predictors
plot(iris)
#initialize model, test different ks and predictors
iris_cluster_model <- kmeans(iris[,3:4], centers=3)
iris_cluster_model
#create table of clusters and species
Clusters <- as.factor(iris_cluster_model$cluster)
Clusters
table(Clusters, iris$Species)
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
#plot petal length vs. width, color points by cluster - very close to species
ss1<-subset(iris, iris_cluster_model$cluster == 1)
ss2<-subset(iris, iris_cluster_model$cluster == 2)
ss3<-subset(iris, iris_cluster_model$cluster == 3)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="blue")
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species, xlab = "Petal Length")) + geom_point()
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() + labs(x = "Petal Length")
labs(x = "Petal Length", y = "Petal Width"
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() +
labs(x = "Petal Length", y = "Petal Width")
#plot petal length vs. width, color points by cluster - very close to species
ss1<-subset(iris, iris_cluster_model$cluster == 1)
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() +
labs(x = "Petal Length", y = "Petal Width")
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() +
labs(x = "Petal Length", y = "Petal Width", title = "Cluster by Species")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="blue") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="green") +
labs(x = "Petal Length", y = "Petal Width", title = "Predicted Clusters")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="blue") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="green") +
labs(x = "Petal Length", y = "Petal Width", title = "Predicted Clusters")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="blue") +
labs(x = "Petal Length", y = "Petal Width", title = "Predicted Clusters")
#load ggplot and ggalt for plotting results
library(ggplot2)
library(ggalt)
#load and inspect data
data(iris)
head(iris)
summary(iris)
class(iris)
#plot relationships between combo of predictors based on thise plot it looks
#like petal length and petal width are best predictors
plot(iris)
#initialize model, test different ks and predictors
iris_cluster_model <- kmeans(iris[,3:4], centers=3)
iris_cluster_model
#create table of clusters and species
Clusters <- as.factor(iris_cluster_model$cluster)
Clusters
table(Clusters, iris$Species)
#plot petal length vs. width, color points by species
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() +
labs(x = "Petal Length", y = "Petal Width", title = "Cluster by Species")
#plot petal length vs. width, color points by cluster - very close to species
ss1<-subset(iris, iris_cluster_model$cluster == 1)
ss2<-subset(iris, iris_cluster_model$cluster == 2)
ss3<-subset(iris, iris_cluster_model$cluster == 3)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Clusters)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="blue") +
labs(x = "Petal Length", y = "Petal Width", title = "Predicted Clusters")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="green") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="blue") +
labs(x = "Petal Length", y = "Petal Width", title = "Predicted Clusters")
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() +
geom_encircle(data=ss1, s_shape=0.5, expand=0.0, colour="blue") +
geom_encircle(data=ss2, s_shape=0.5, expand=0.0, colour="red") +
geom_encircle(data=ss3, s_shape=0.5, expand=0.0, colour="green") +
labs(x = "Petal Length", y = "Petal Width", title = "Predicted Clusters")
